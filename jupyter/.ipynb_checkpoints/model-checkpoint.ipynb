{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#导入相关的包\" data-toc-modified-id=\"导入相关的包-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>导入相关的包</a></span></li><li><span><a href=\"#导入相关数据\" data-toc-modified-id=\"导入相关数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>导入相关数据</a></span></li><li><span><a href=\"#使用模型\" data-toc-modified-id=\"使用模型-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>使用模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lasso\" data-toc-modified-id=\"Lasso-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Lasso</a></span></li><li><span><a href=\"#LassorLar\" data-toc-modified-id=\"LassorLar-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>LassorLar</a></span></li><li><span><a href=\"#贝叶斯回归\" data-toc-modified-id=\"贝叶斯回归-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>贝叶斯回归</a></span></li><li><span><a href=\"#ENet\" data-toc-modified-id=\"ENet-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>ENet</a></span></li><li><span><a href=\"#MLP\" data-toc-modified-id=\"MLP-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>MLP</a></span></li><li><span><a href=\"#SVR\" data-toc-modified-id=\"SVR-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>SVR</a></span></li><li><span><a href=\"#Ridge\" data-toc-modified-id=\"Ridge-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Ridge</a></span></li><li><span><a href=\"#RF\" data-toc-modified-id=\"RF-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>RF</a></span></li><li><span><a href=\"#GBoost\" data-toc-modified-id=\"GBoost-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>GBoost</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-3.12\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;</span>Stacking</a></span></li><li><span><a href=\"#AverageModel\" data-toc-modified-id=\"AverageModel-3.13\"><span class=\"toc-item-num\">3.13&nbsp;&nbsp;</span>AverageModel</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "trains = pd.read_csv('../clean_data/base_train.csv',encoding=\"gbk\")\n",
    "labels = \"blood_sugar\"\n",
    "features = [x for x in list(trains.columns) if x not in ['id','date','blood_sugar','blood_sugar_log']]\n",
    "features_with_no_cate = [x for x in list(trains.columns) if x not in ['id','date','blood_sugar','blood_sugar_log','gender','age']]\n",
    "x_val, x_test, y_val, y_test = train_test_split(vals[features], vals[labels],test_size=0.1, random_state=42)\n",
    "def re(y):\n",
    "    return np.exp(np.exp(np.exp(-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first = [\"feature_34\",\"feature_35\",\"feature_36\",'feature_7','feature_26',\n",
    "         'feature_30','feature_29','feature_31', 'feature_28','feature_22',]\n",
    "second = [\"feature_34\",\"feature_35\",\"feature_36\",'feature_7','feature_25']\n",
    "third = [\"feature_34\",\"feature_35\",\"feature_36\",'feature_7','feature_25',\n",
    "         'feature_30','feature_29','feature_31', 'feature_28','feature_22']\n",
    "for i in third:\n",
    "    features_with_no_cate.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_32',\n",
       " 'feature_33']"
      ]
     },
     "execution_count": 1367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_no_cate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = pd.read_csv('../clean_data/model_fill_train.csv',encoding='gbk')\n",
    "trains = pd.concat([trains, vals],axis=0)\n",
    "train = trains[features_with_no_cate]\n",
    "y_train = trains[labels]\n",
    "test = x_test[features_with_no_cate]\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5606, 22)"
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test = pd.read_csv('../clean_data/test.csv',encoding='gbk')\n",
    "test_sub = sub_test[features_with_no_cate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.850</td>\n",
       "      <td>26.690</td>\n",
       "      <td>116.080</td>\n",
       "      <td>34.360</td>\n",
       "      <td>82.750</td>\n",
       "      <td>46.030</td>\n",
       "      <td>36.720</td>\n",
       "      <td>1.070</td>\n",
       "      <td>5.030</td>\n",
       "      <td>1.440</td>\n",
       "      <td>...</td>\n",
       "      <td>65.87</td>\n",
       "      <td>303.37</td>\n",
       "      <td>9.39</td>\n",
       "      <td>4.94</td>\n",
       "      <td>0.453</td>\n",
       "      <td>91.7</td>\n",
       "      <td>333.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>58.4</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.750</td>\n",
       "      <td>34.980</td>\n",
       "      <td>90.070</td>\n",
       "      <td>111.430</td>\n",
       "      <td>71.900</td>\n",
       "      <td>44.090</td>\n",
       "      <td>27.810</td>\n",
       "      <td>2.480</td>\n",
       "      <td>5.510</td>\n",
       "      <td>1.220</td>\n",
       "      <td>...</td>\n",
       "      <td>89.99</td>\n",
       "      <td>368.76</td>\n",
       "      <td>7.58</td>\n",
       "      <td>5.84</td>\n",
       "      <td>0.518</td>\n",
       "      <td>88.7</td>\n",
       "      <td>330.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.187</td>\n",
       "      <td>33.966</td>\n",
       "      <td>92.145</td>\n",
       "      <td>43.766</td>\n",
       "      <td>78.465</td>\n",
       "      <td>47.218</td>\n",
       "      <td>30.994</td>\n",
       "      <td>1.992</td>\n",
       "      <td>5.381</td>\n",
       "      <td>1.301</td>\n",
       "      <td>...</td>\n",
       "      <td>73.29</td>\n",
       "      <td>383.92</td>\n",
       "      <td>9.06</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.506</td>\n",
       "      <td>88.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>50.2</td>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.980</td>\n",
       "      <td>16.630</td>\n",
       "      <td>95.950</td>\n",
       "      <td>23.410</td>\n",
       "      <td>78.160</td>\n",
       "      <td>45.440</td>\n",
       "      <td>32.720</td>\n",
       "      <td>5.940</td>\n",
       "      <td>6.800</td>\n",
       "      <td>1.380</td>\n",
       "      <td>...</td>\n",
       "      <td>70.82</td>\n",
       "      <td>322.09</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.420</td>\n",
       "      <td>91.1</td>\n",
       "      <td>329.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>53.7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.120</td>\n",
       "      <td>19.800</td>\n",
       "      <td>76.970</td>\n",
       "      <td>15.700</td>\n",
       "      <td>80.760</td>\n",
       "      <td>46.900</td>\n",
       "      <td>33.860</td>\n",
       "      <td>0.740</td>\n",
       "      <td>6.230</td>\n",
       "      <td>2.250</td>\n",
       "      <td>...</td>\n",
       "      <td>73.91</td>\n",
       "      <td>377.39</td>\n",
       "      <td>6.24</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.440</td>\n",
       "      <td>95.2</td>\n",
       "      <td>334.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0     23.850     26.690    116.080     34.360     82.750     46.030   \n",
       "1     29.750     34.980     90.070    111.430     71.900     44.090   \n",
       "2     31.187     33.966     92.145     43.766     78.465     47.218   \n",
       "3     17.980     16.630     95.950     23.410     78.160     45.440   \n",
       "4     19.120     19.800     76.970     15.700     80.760     46.900   \n",
       "\n",
       "   feature_6  feature_8  feature_9  feature_10     ...      feature_13  \\\n",
       "0     36.720      1.070      5.030       1.440     ...           65.87   \n",
       "1     27.810      2.480      5.510       1.220     ...           89.99   \n",
       "2     30.994      1.992      5.381       1.301     ...           73.29   \n",
       "3     32.720      5.940      6.800       1.380     ...           70.82   \n",
       "4     33.860      0.740      6.230       2.250     ...           73.91   \n",
       "\n",
       "   feature_14  feature_20  feature_21  feature_23  feature_24  feature_26  \\\n",
       "0      303.37        9.39        4.94       0.453        91.7       333.0   \n",
       "1      368.76        7.58        5.84       0.518        88.7       330.0   \n",
       "2      383.92        9.06        5.72       0.506        88.5       338.0   \n",
       "3      322.09        4.60        4.61       0.420        91.1       329.0   \n",
       "4      377.39        6.24        4.62       0.440        95.2       334.0   \n",
       "\n",
       "   feature_27  feature_32  feature_33  \n",
       "0        12.3        58.4        33.2  \n",
       "1        12.0        59.3        29.3  \n",
       "2        12.1        50.2        40.1  \n",
       "3        12.6        53.7        38.0  \n",
       "4        12.2        52.0        39.4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 1372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 1372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub.head()\n",
    "test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_onehot_train = pd.get_dummies(trains['gender'])\n",
    "gender_onehot_train.rename(columns={0:'gender_0',1:'gender_1'},inplace=True)\n",
    "train = pd.concat([train, gender_onehot_train, trains['age']],axis=1)\n",
    "gender_onehot_test = pd.get_dummies(x_test['gender'])\n",
    "gender_onehot_test.rename(columns={0:'gender_0',1:'gender_1'},inplace=True)\n",
    "test = pd.concat([test, gender_onehot_test, x_test['age']],axis=1)\n",
    "gender_onehot_test = pd.get_dummies(sub_test['gender'])\n",
    "gender_onehot_test.rename(columns={0:'gender_0',1:'gender_1'},inplace=True)\n",
    "test_sub = pd.concat([test_sub, gender_onehot_test, sub_test['age']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_data = pd.concat([train, test],axis=0)\n",
    "# age_data = pd.get_dummies(all_data['age'])\n",
    "# all_data = pd.concat([all_data, age_data],axis=1)\n",
    "# all_data.drop('age',inplace=True,axis=1)\n",
    "# train = all_data[:train.shape[0]]\n",
    "# test = all_data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5606, 25)"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(170, 25)"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "def rmsle(y,y_pred):\n",
    "#     return 0.5 * mean_squared_error(re(y), re(y_pred))\n",
    "    return 0.5 * mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "\n",
      "Lasso score: 1.1293 (0.0557)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=42,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.629316467695\n",
      "test:  0.48687953509\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=42))\n",
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "lasso.fit(train,y_train)\n",
    "lasso_train_pred = lasso.predict(train)\n",
    "lasso_pred = lasso.predict(test)\n",
    "print(\"train: \",rmsle(y_train, lasso_train_pred))\n",
    "print(\"test: \", rmsle(y_test,lasso_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassorLar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "LassorLar score: 1.2479 (0.0632)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.1, copy_X=True, eps=2.2204460492503131e-16,\n",
       "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
       "     positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.778154696431\n",
      "test:  0.61750161267\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn import linear_model\n",
    "LassorLar = linear_model.LassoLars(alpha=.1)\n",
    "score = rmsle_cv(LassorLar)\n",
    "print(\"LassorLar score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "LassorLar.fit(train,y_train)\n",
    "LassorLar_train_pred = LassorLar.predict(train)\n",
    "LassorLar_pred = LassorLar.predict(test)\n",
    "print(\"train: \",rmsle(y_train, LassorLar_train_pred))\n",
    "print(\"test: \", rmsle(y_test,LassorLar_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Bayreg score: 1.1298 (0.0555)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.630101825288\n",
      "test:  0.489511973989\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# 贝叶斯回归\n",
    "from sklearn import linear_model\n",
    "Bayreg = linear_model.BayesianRidge()\n",
    "score = rmsle_cv(Bayreg)\n",
    "print(\"Bayreg score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "Bayreg.fit(train,y_train)\n",
    "Bayreg_train_pred = Bayreg.predict(train)\n",
    "Bayreg_pred = Bayreg.predict(test)\n",
    "print(\"train: \",rmsle(y_train, Bayreg_train_pred))\n",
    "print(\"test: \", rmsle(y_test,Bayreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "ElasticNet score: 1.1294 (0.0557)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('elasticnet', ElasticNet(alpha=0.005, copy_X=True, fit_intercept=True, l1_ratio=0.9,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=42, selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 1380,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.630013375009\n",
      "test:  0.488500568723\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.005, l1_ratio=.9, random_state=42))\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "ENet.fit(train,y_train)\n",
    "ENet_train_pred = ENet.predict(train)\n",
    "ENet_pred = ENet.predict(test)\n",
    "print(\"train: \",rmsle(y_train, ENet_train_pred))\n",
    "print(\"test: \", rmsle(y_test,ENet_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp score: 1.1592 (0.0753)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('mlpregressor', MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
       "   ...       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False))])"
      ]
     },
     "execution_count": 1381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.5099416197\n",
      "test:  0.415517343279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp =  make_pipeline(StandardScaler(), MLPRegressor(random_state=42,learning_rate =\"adaptive\",max_iter=500))\n",
    "score = rmsle_cv(mlp)\n",
    "print(\"mlp score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "mlp.fit(train,y_train)\n",
    "mlp_train_pred = mlp.predict(train)\n",
    "mlp_pred = mlp.predict(test)\n",
    "print(\"train: \",rmsle(y_train, mlp_train_pred))\n",
    "print(\"test: \", rmsle(y_test,mlp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "svr score: 1.2592 (0.0775)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.410298652403\n",
      "test:  0.302979265323\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn import svm\n",
    "svr = svm.SVR()\n",
    "score = rmsle_cv(svr)\n",
    "print(\"svr score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "svr.fit(train,y_train)\n",
    "svr_train_pred = svr.predict(train)\n",
    "svr_pred = svr.predict(test)\n",
    "print(\"train: \",rmsle(y_train, svr_train_pred))\n",
    "print(\"test: \", rmsle(y_test,svr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Kernel Ridge score: 1.2310 (0.1326)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.6, coef0=2.5, degree=2, gamma=None, kernel='polynomial',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 1383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.546925216452\n",
      "test:  0.432588881411\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "KRR.fit(train,y_train)\n",
    "KRR_train_pred = KRR.predict(train)\n",
    "KRR_pred = KRR.predict(test)\n",
    "print(\"train: \",rmsle(y_train, KRR_train_pred))\n",
    "print(\"test: \", rmsle(y_test,KRR_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      " rf score: 1.2067 (0.0822)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=530, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.125073132983\n",
      "test:  0.0993072764706\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "rf = RandomForestRegressor(random_state=530)\n",
    "score = rmsle_cv(rf)\n",
    "print(\"\\r rf score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "rf.fit(train,y_train)\n",
    "rf_train_pred = rf.predict(train)\n",
    "rf_pred = rf.predict(test)\n",
    "print(\"train: \",rmsle(y_train, rf_train_pred))\n",
    "print(\"test: \", rmsle(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Gradient Boosting score: 1.1434 (0.0552)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='huber', max_depth=4,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=15, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "             presort='auto', random_state=5, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 1385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.537954709384\n",
      "test:  0.43665461425\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "GBoost = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "GBoost.fit(train, y_train)\n",
    "GBoost_train_pred = GBoost.predict(train)\n",
    "GBoost_pred = GBoost.predict(test)\n",
    "print(\"train: \",rmsle(y_train, GBoost_train_pred))\n",
    "print(\"test: \", rmsle(y_test,GBoost_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Xgboost score: 1.1293 (0.0513)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4603,\n",
       "       gamma=0.0468, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1.7817, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0.464, reg_lambda=0.8571,\n",
       "       scale_pos_weight=1, seed=1024, silent=1, subsample=0.5213)"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.544248198793\n",
      "test:  0.447422817343\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.01, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=500,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             seed =1024, nthread = -1)\n",
    "\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = model_xgb.predict(test)\n",
    "print(\"train: \",rmsle(y_train, xgb_train_pred))\n",
    "print(\"test: \", rmsle(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "LGBM score: 1.1261 (0.0582)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "       boosting_type='gbdt', colsample_bytree=1, feature_fraction=0.2319,\n",
       "       feature_fraction_seed=9, learning_rate=0.05, max_bin=55,\n",
       "       max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "       min_data_in_leaf=6, min_split_gain=0, min_sum_hessian_in_leaf=11,\n",
       "       n_estimators=720, nthread=-1, num_leaves=5, objective='regression',\n",
       "       reg_alpha=0, reg_lambda=0, seed=0, silent=True, subsample=1,\n",
       "       subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 1387,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.432681958004\n",
      "test:  0.367262344926\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = model_lgb.predict(test.values)\n",
    "print(\"train: \",rmsle(y_train, lgb_train_pred))\n",
    "print(\"test: \",rmsle(y_test, lgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking score: 1.1184 (0.0739)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(meta_regressor=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4603,\n",
       "       gamma=0.0468, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1.7817, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0.464, reg_lambda=0.8571,\n",
       "       scale_pos_weight=1, seed=1024, silent=1, subsample=0.5213),\n",
       "         regressors=[Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, ran...nelRidge(alpha=0.6, coef0=2.5, degree=2, gamma=None, kernel='polynomial',\n",
       "      kernel_params=None)],\n",
       "         verbose=0)"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.428084702812\n",
      "test:  0.360429427419\n"
     ]
    }
   ],
   "source": [
    "regressors = [lasso, ENet, GBoost, KRR]\n",
    "stregr = StackingRegressor(regressors=regressors, meta_regressor=model_xgb)\n",
    "score = rmsle_cv(stregr)\n",
    "print(\"stacking score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "stregr.fit(train, y_train)\n",
    "stregr_train_pred = stregr.predict(train)\n",
    "stregr_pred = stregr.predict(test)\n",
    "print(\"train: \",rmsle(y_train, stregr_train_pred))\n",
    "print(\"test: \", rmsle(y_test,stregr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AverageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      " Averaged base models score: 1.1101 (0.0576)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AveragingModels(models=(XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4603,\n",
       "       gamma=0.0468, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1.7817, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0.464, reg_lambda=0.8571,\n",
       "  ...nelRidge(alpha=0.6, coef0=2.5, degree=2, gamma=None, kernel='polynomial',\n",
       "      kernel_params=None)))"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.496025116778\n",
      "test:  0.412538299127\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "averaged_models = AveragingModels(models = (model_lgb, rf, stregr, KRR))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "averaged_models.fit(train,y_train)\n",
    "ave_train_pred = averaged_models.predict(train)\n",
    "ave_pred = averaged_models.predict(test)\n",
    "print(\"train: \",rmsle(y_train, ave_train_pred))\n",
    "print(\"test: \", rmsle(y_test,ave_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = averaged_models.predict(test_sub)\n",
    "sub_pd = pd.DataFrame(sub)\n",
    "sub_pd.to_csv('../submission/sub_average_7_1_c.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.570879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.525033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.672465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.186102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.497046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.842449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.777463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1000.000000\n",
       "mean      5.570879\n",
       "std       0.525033\n",
       "min       4.672465\n",
       "25%       5.186102\n",
       "50%       5.497046\n",
       "75%       5.842449\n",
       "max       8.777463"
      ]
     },
     "execution_count": 1392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.515492800171\n",
      "RMSLE score on test data:\n",
      "0.414737444553\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,xgb_train_pred*0.70 +\n",
    "               lgb_train_pred*0.15 + ave_train_pred*0.15 ))\n",
    "print('RMSLE score on test data:')\n",
    "print(rmsle(y_test,ave_pred*0.65 +\n",
    "               lgb_pred*0.10 + xgb_pred*0.25 ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
